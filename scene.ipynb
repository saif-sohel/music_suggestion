{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import random\r\n",
    "import cv2\r\n",
    "import tqdm as tqdm\r\n",
    "from tensorflow.keras.preprocessing.image import load_img\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach = \"scene/train/beach\"\r\n",
    "building = \"scene/train/building\"\r\n",
    "forest = \"scene/train/forest\"\r\n",
    "mountain = \"scene/train/mountain\"\r\n",
    "park = \"scene/train/park\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images in Each Directory:\n",
      "beach: 4500\n",
      "building: 4500\n",
      "forest: 4500\n",
      "mountain: 4500\n",
      "park: 4500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Images in Each Directory:\")\r\n",
    "print(f\"beach: {len(os.listdir(beach))}\")\r\n",
    "print(f\"building: {len(os.listdir(building))}\")\r\n",
    "print(f\"forest: {len(os.listdir(forest))}\")\r\n",
    "print(f\"mountain: {len(os.listdir(mountain))}\")\r\n",
    "print(f\"park: {len(os.listdir(park))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\r\n",
    "y = [] \r\n",
    "dataset =[]\r\n",
    "def create_dataset(directory,dir_name):\r\n",
    "    for i in tqdm.tqdm(os.listdir(directory)):\r\n",
    "        full_path = os.path.join(directory,i)\r\n",
    "        try:\r\n",
    "            img = cv2.imread(full_path)\r\n",
    "            img = cv2.resize(img,(128,128))\r\n",
    "        except:\r\n",
    "            continue\r\n",
    "        x.append(img)\r\n",
    "        y.append(dir_name)\r\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [00:06<00:00, 742.33it/s]\n",
      "100%|██████████| 4500/4500 [00:06<00:00, 709.89it/s]\n",
      "100%|██████████| 4500/4500 [00:07<00:00, 616.35it/s]\n",
      "100%|██████████| 4500/4500 [00:06<00:00, 708.44it/s]\n",
      "100%|██████████| 4500/4500 [00:06<00:00, 704.11it/s]\n"
     ]
    }
   ],
   "source": [
    "x,y= create_dataset(beach,\"beach\")\r\n",
    "x,y= create_dataset(building,\"building\")\r\n",
    "x,y= create_dataset(forest,\"forest\")\r\n",
    "x,y= create_dataset(mountain,\"mountain\")\r\n",
    "x,y= create_dataset(park,\"park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((22500, 128, 128, 3), (22500,))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  np.array(x)\r\n",
    "y = np.array(y)\r\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,7))\r\n",
    "for i in range(15):\r\n",
    "    sample =  random.choice(range(len(x)))\r\n",
    "    image = x[sample]\r\n",
    "    category = y[sample]\r\n",
    "    plt.subplot(3,5,i+1)\r\n",
    "    plt.subplots_adjust(hspace=0.3)\r\n",
    "    plt.imshow(image)\r\n",
    "    plt.xlabel(category)\r\n",
    "    \r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "le = LabelEncoder()\r\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size =128\r\n",
    "\r\n",
    "x_train = np.array(x_train)/255.0\r\n",
    "x_test = np.array(x_test)/255.0\r\n",
    "\r\n",
    "\r\n",
    "x_train = x_train.reshape(-1,img_size,img_size,3)\r\n",
    "y_train = np.array(y_train)\r\n",
    "\r\n",
    "x_test = x_test.reshape(-1,img_size,img_size,3)\r\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "lb = LabelBinarizer()\r\n",
    "y_train_lb = lb.fit_transform(y_train)\r\n",
    "y_test_lb = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((18000, 5), (4500, 5))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lb.shape,y_test_lb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\r\n",
    "vgg = VGG19(weights = \"imagenet\",include_top=False,input_shape=(img_size,img_size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\r\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\r\n",
    "from tensorflow.keras.layers import Flatten,Dense\r\n",
    "model =Sequential()\r\n",
    "model.add(vgg)\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(5,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 40965     \n",
      "=================================================================\n",
      "Total params: 20,065,349\n",
      "Trainable params: 40,965\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=\"accuracy\")\r\n",
    "\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\r\n",
    "checkpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_accuracy\",verbose=1,save_best_only=True,\r\n",
    "                             save_weights_only=False)\r\n",
    "earlystop = EarlyStopping(monitor=\"val_accuracy\",patience=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [72000 18000]\n"
     ]
    }
   ],
   "source": [
    "unique,counts = np.unique(y_train_lb,return_counts=True)\r\n",
    "print(unique,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.8124\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83822, saving model to vgg19.h5\n",
      "563/563 [==============================] - 105s 187ms/step - loss: 0.5426 - accuracy: 0.8124 - val_loss: 0.4881 - val_accuracy: 0.8382\n",
      "Epoch 2/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.4082 - accuracy: 0.8618\n",
      "Epoch 00002: val_accuracy improved from 0.83822 to 0.83889, saving model to vgg19.h5\n",
      "563/563 [==============================] - 86s 152ms/step - loss: 0.4082 - accuracy: 0.8618 - val_loss: 0.4733 - val_accuracy: 0.8389\n",
      "Epoch 3/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8817\n",
      "Epoch 00003: val_accuracy improved from 0.83889 to 0.84244, saving model to vgg19.h5\n",
      "563/563 [==============================] - 86s 153ms/step - loss: 0.3438 - accuracy: 0.8817 - val_loss: 0.4727 - val_accuracy: 0.8424\n",
      "Epoch 4/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.8922\n",
      "Epoch 00004: val_accuracy did not improve from 0.84244\n",
      "563/563 [==============================] - 86s 153ms/step - loss: 0.3132 - accuracy: 0.8922 - val_loss: 0.4833 - val_accuracy: 0.8411\n",
      "Epoch 5/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9022\n",
      "Epoch 00005: val_accuracy did not improve from 0.84244\n",
      "563/563 [==============================] - 86s 153ms/step - loss: 0.2818 - accuracy: 0.9022 - val_loss: 0.5138 - val_accuracy: 0.8367\n",
      "Epoch 6/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.9134\n",
      "Epoch 00006: val_accuracy did not improve from 0.84244\n",
      "563/563 [==============================] - 86s 153ms/step - loss: 0.2560 - accuracy: 0.9134 - val_loss: 0.5013 - val_accuracy: 0.8389\n",
      "Epoch 7/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9196\n",
      "Epoch 00007: val_accuracy did not improve from 0.84244\n",
      "563/563 [==============================] - 86s 153ms/step - loss: 0.2364 - accuracy: 0.9196 - val_loss: 0.5343 - val_accuracy: 0.8313\n",
      "Epoch 8/15\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9241\n",
      "Epoch 00008: val_accuracy did not improve from 0.84244\n",
      "563/563 [==============================] - 86s 153ms/step - loss: 0.2218 - accuracy: 0.9241 - val_loss: 0.5603 - val_accuracy: 0.8307\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\r\n",
    "history =  model.fit(x_train,y_train_lb,epochs=15,validation_data=(x_test,y_test_lb),\r\n",
    "                     batch_size=32 ,verbose=1,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \r\n",
    "\r\n",
    "if tf.test.gpu_device_name(): \r\n",
    "\r\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\r\n",
    "\r\n",
    "else:\r\n",
    "\r\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\r\n",
    "model1 = load_model(\"scene_recog.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5c5d734624cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_pred_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_lb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_keras\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\cvpr\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cvpr\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    774\u001b[0m     \"\"\"\n\u001b[0;32m    775\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 776\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cvpr\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\r\n",
    "y_pred_keras = model1.predict(x_test).ravel()\r\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test_lb, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}